{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 3\n",
    "\n",
    "### Regression and Classification with the Ames Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "You have just joined a new \"full stack\" real estate company in Ames, Iowa. The strategy of the firm is two-fold:\n",
    "- Own the entire process from the purchase of the land all the way to sale of the house, and anything in between.\n",
    "- Use statistical analysis to optimize investment and maximize return.\n",
    "\n",
    "The company is still small, and though investment is substantial the short-term goals of the company are more oriented towards purchasing existing houses and flipping them as opposed to constructing entirely new houses. That being said, the company has access to a large construction workforce operating at rock-bottom prices.\n",
    "\n",
    "This project uses the [Ames housing data recently made available on kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LassoCV, Lasso, RidgeCV, Ridge, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Estimating the value of homes from fixed characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "Your superiors have outlined this year's strategy for the company:\n",
    "1. Develop an algorithm to reliably estimate the value of residential houses based on *fixed* characteristics.\n",
    "2. Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.\n",
    "3. Evaluate the mean dollar value of different renovations.\n",
    "\n",
    "Then we can use that to buy houses that are likely to sell for more than the cost of the purchase plus renovations.\n",
    "\n",
    "Your first job is to tackle #1. You have a dataset of housing sale data with a huge amount of features identifying different aspects of the house. The full description of the data features can be found in a separate file:\n",
    "\n",
    "    housing.csv\n",
    "    data_description.txt\n",
    "    \n",
    "You need to build a reliable estimator for the price of the house given characteristics of the house that cannot be renovated. Some examples include:\n",
    "- The neighborhood\n",
    "- Square feet\n",
    "- Bedrooms, bathrooms\n",
    "- Basement and garage space\n",
    "\n",
    "and many more. \n",
    "\n",
    "Some examples of things that **ARE renovate-able:**\n",
    "- Roof and exterior features\n",
    "- \"Quality\" metrics, such as kitchen quality\n",
    "- \"Condition\" metrics, such as condition of garage\n",
    "- Heating and electrical components\n",
    "\n",
    "and generally anything you deem can be modified without having to undergo major construction on the house.\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Perform any cleaning, feature engineering, and EDA you deem necessary.\n",
    "- Be sure to remove any houses that are not residential from the dataset.\n",
    "- Identify **fixed** features that can predict price.\n",
    "- Train a model on pre-2010 data and evaluate its performance on the 2010 houses.\n",
    "- Characterize your model. How well does it perform? What are the best estimates of price?\n",
    "\n",
    "> **Note:** The EDA and feature engineering component to this project is not trivial! Be sure to always think critically and creatively. Justify your actions! Use the data description file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass: Identifies the type of dwelling involved in the sale.\\t',\n",
       " '',\n",
       " '        20\\t1-STORY 1946 & NEWER ALL STYLES',\n",
       " '        30\\t1-STORY 1945 & OLDER',\n",
       " '        40\\t1-STORY W/FINISHED ATTIC ALL AGES']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "with open('data_description.txt') as f:\n",
    "    reader = f.read()\n",
    "    data_dict = [i for i in reader.splitlines()]\n",
    "data_dict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data_dictionary filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiscFeature: Miscellaneous feature not covered in other categories\n",
      "\t\t\n",
      "       Elev\tElevator\n",
      "       Gar2\t2nd Garage (if not described in garage section)\n",
      "       Othr\tOther\n",
      "       Shed\tShed (over 100 SF)\n",
      "       TenC\tTennis Court\n",
      "       NA\tNone\n",
      "\t\t\n",
      "MiscVal: $Value of miscellaneous feature\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def dict_filter(string, lines=10, find_one=True):\n",
    "    for c, i in enumerate(data_dict):\n",
    "        if re.search(string, i):\n",
    "            [print(j) for j in data_dict[c:c+lines]]\n",
    "            print(' ')\n",
    "            if find_one == True: break\n",
    "dict_filter('Misc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop many columns\n",
    "    1. drop columns with only 1 unique value\n",
    "    2. drop columns with Sale in their name (data leakage)\n",
    "    3. drop columns with mostly null values\n",
    "    4. drop columns with an extremely high number of same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = df.columns[df.apply(lambda x: x.nunique()==1) | df.apply(lambda x: x.nunique()==len(df))]\n",
    "df.drop(to_drop, axis=1, inplace = True)\n",
    "\n",
    "to_drop = df.columns[df.columns.str.contains('[Ss]ale')].difference(['SalePrice'])\n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "_ = df.apply(lambda x: x.isnull().sum()/df.shape[0]).sort_values(ascending=False)\n",
    "to_drop = _[(_!=1) & (_!=0)]\n",
    "df.drop(to_drop.head(2).index, axis=1, inplace=True)\n",
    "\n",
    "to_drop = df.apply(lambda x: x.value_counts(dropna=False).iloc[0]/df.shape[0]).sort_values(ascending=False).head(10).index\n",
    "df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some columns to convert binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_vals</th>\n",
       "      <th>null_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Alley</td>\n",
       "      <td>Grvl, Pave</td>\n",
       "      <td>0.937671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CentralAir</td>\n",
       "      <td>Y, N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             uniq_vals null_vals\n",
       "Alley       Grvl, Pave  0.937671\n",
       "CentralAir        Y, N         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = df.columns[df.apply(lambda x: x.nunique() == 2)]\n",
    "df[binary].apply(lambda x: pd.Series([', '.join(x.dropna().unique()), x.isnull().sum()/df.shape[0]], index=['uniq_vals', 'null_vals'])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CentralAir = df.CentralAir.map(lambda x: 0 if x == 'N' else 1)\n",
    "df.Alley = df.Alley.map(lambda x: 0 if re.search('nan', str(x)) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df.columns[df.columns.str.contains('[Yy]r|[Yy]ear')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The numeric columns containing nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    259\n",
       "MasVnrArea       8\n",
       "WoodDeckSF       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = df.dtypes[df.dtypes!='object'].index.difference(time)\n",
    "df[numeric].isnull().sum().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage    259\n",
       "LotArea          0\n",
       "LotShape         0\n",
       "LotConfig        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, df.columns.str.contains('Lot')].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Remove LotFrontage, too many unexplainable null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('LotFrontage', axis=1, inplace=True)\n",
    "numeric = numeric.drop('LotFrontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MasVnrType    8\n",
       "MasVnrArea    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.MasVnrType.isnull() & df.MasVnrArea.isnull()).sum()\n",
    "df.loc[:, df.columns.str.contains('MasVnr')].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Replace nulls with 0, since area for a non-existent feature is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.MasVnrArea.fillna(0, inplace=True)\n",
    "df[numeric].isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.columns[df.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fence           1179\n",
       "FireplaceQu      690\n",
       "GarageCond        81\n",
       "GarageQual        81\n",
       "GarageFinish      81\n",
       "GarageType        81\n",
       "BsmtExposure      38\n",
       "BsmtFinType2      38\n",
       "BsmtFinType1      37\n",
       "BsmtCond          37\n",
       "BsmtQual          37\n",
       "MasVnrType         8\n",
       "Electrical         1\n",
       "LandContour        0\n",
       "LotConfig          0\n",
       "RoofStyle          0\n",
       "LotShape           0\n",
       "LandSlope          0\n",
       "Neighborhood       0\n",
       "Condition1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isnull = df[categorical].isnull().sum().sort_values(ascending=False).head(20)\n",
    "isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fence                                    MnPrv, GdWo, GdPrv, MnWw\n",
       "FireplaceQu                                    TA, Gd, Fa, Ex, Po\n",
       "GarageCond                                     TA, Fa, Gd, Po, Ex\n",
       "GarageQual                                     TA, Fa, Gd, Ex, Po\n",
       "GarageFinish                                        RFn, Unf, Fin\n",
       "GarageType      Attchd, Detchd, BuiltIn, CarPort, Basment, 2Types\n",
       "BsmtExposure                                       No, Gd, Mn, Av\n",
       "BsmtFinType2                         Unf, BLQ, ALQ, Rec, LwQ, GLQ\n",
       "BsmtFinType1                         GLQ, ALQ, Unf, Rec, BLQ, LwQ\n",
       "BsmtCond                                           TA, Gd, Fa, Po\n",
       "BsmtQual                                           Gd, TA, Ex, Fa\n",
       "MasVnrType                           BrkFace, None, Stone, BrkCmn\n",
       "Electrical                        SBrkr, FuseF, FuseA, FuseP, Mix\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[isnull[isnull!=0].index].apply(lambda x: ', '.join(x.dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LandContour                                    Lvl, Bnk, Low, HLS\n",
       "LotConfig                       Inside, FR2, Corner, CulDSac, FR3\n",
       "RoofStyle                Gable, Hip, Gambrel, Mansard, Flat, Shed\n",
       "LotShape                                       Reg, IR1, IR2, IR3\n",
       "LandSlope                                           Gtl, Mod, Sev\n",
       "Neighborhood    CollgCr, Veenker, Crawfor, NoRidge, Mitchel, S...\n",
       "Condition1      Norm, Feedr, PosN, Artery, RRAe, RRNn, RRAn, P...\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[isnull[isnull==0].index].apply(lambda x: ', '.join(x.dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      1179\n",
       "MnPrv     157\n",
       "GdPrv      59\n",
       "GdWo       54\n",
       "MnWw       11\n",
       "Name: Fence, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Fence.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fence: Fence quality\n",
      "\t\t\n",
      "       GdPrv\tGood Privacy\n",
      "       MnPrv\tMinimum Privacy\n",
      "       GdWo\tGood Wood\n",
      "       MnWw\tMinimum Wood/Wire\n",
      "       NA\tNo Fence\n",
      "\t\n",
      "MiscFeature: Miscellaneous feature not covered in other categories\n",
      "\t\t\n",
      " \n"
     ]
    }
   ],
   "source": [
    "dict_filter('Fence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe to convert object columns to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df[categorical])], axis=1)\n",
    "df.drop(categorical, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('GarageYrBlt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqs = df.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data train and test\n",
    "    Test set is 2010 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2010 = df[df.YrSold==2010]\n",
    "df = df.loc[df.index.difference(df2010.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = ['1stFlrSF', '2ndFlrSF', 'Alley', 'BedroomAbvGr', 'BldgType_1Fam', 'BldgType_2fmCon', 'BldgType_Duplex', 'BldgType_Twnhs', 'BldgType_TwnhsE', 'BsmtExposure_Av', 'BsmtExposure_Gd', 'BsmtExposure_Mn', 'BsmtExposure_No', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'Condition1_Artery', 'Condition1_Feedr', 'Condition1_Norm', 'Condition1_PosA', 'Condition1_PosN', 'Condition1_RRAe', 'Condition1_RRAn', 'Condition1_RRNe', 'Condition1_RRNn', 'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP', 'Electrical_Mix', 'Electrical_SBrkr', 'EnclosedPorch', 'Exterior1st_CBlock', 'Exterior1st_CemntBd', 'Exterior1st_Wd Sdng', 'Exterior2nd_AsbShng', 'Exterior2nd_HdBoard', 'Exterior2nd_MetalSd', 'Exterior2nd_VinylSd', 'Fireplaces', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood', 'FullBath', 'GarageArea', 'GarageCars', 'GarageType_2Types', 'GarageType_Attchd', 'GarageType_Basment', 'GarageType_BuiltIn', 'GarageType_CarPort', 'GarageType_Detchd', 'GrLivArea', 'HalfBath', 'HouseStyle_1.5Fin', 'HouseStyle_1.5Unf', 'HouseStyle_1Story', 'HouseStyle_2.5Fin', 'HouseStyle_2.5Unf', 'HouseStyle_2Story', 'HouseStyle_SFoyer', 'HouseStyle_SLvl', 'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl', 'LandSlope_Gtl', 'LandSlope_Mod', 'LandSlope_Sev', 'LotArea', 'LotConfig_Corner', 'LotConfig_CulDSac', 'LotConfig_FR2', 'LotConfig_FR3', 'LotConfig_Inside', 'LotShape_IR1', 'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg', 'MSSubClass', 'MSZoning_C (all)', 'MSZoning_FV', 'MSZoning_RH', 'MSZoning_RL', 'MSZoning_RM', 'MasVnrArea', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace', 'MasVnrType_None', 'MasVnrType_Stone', 'MoSold', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'OpenPorchSF', 'PavedDrive_N', 'PavedDrive_P', 'PavedDrive_Y', 'RoofStyle_Flat', 'RoofStyle_Gable', 'RoofStyle_Gambrel', 'RoofStyle_Hip', 'RoofStyle_Mansard', 'RoofStyle_Shed', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']\n",
    "variable = ['BsmtCond_Fa', 'BsmtCond_Gd', 'BsmtCond_Po', 'BsmtCond_TA', 'BsmtFinType1_ALQ', 'BsmtFinType1_BLQ', 'BsmtFinType1_GLQ', 'BsmtFinType1_LwQ', 'BsmtFinType1_Rec', 'BsmtFinType1_Unf', 'BsmtFinType2_ALQ', 'BsmtFinType2_BLQ', 'BsmtFinType2_GLQ', 'BsmtFinType2_LwQ', 'BsmtFinType2_Rec', 'BsmtFinType2_Unf', 'BsmtQual_Ex', 'BsmtQual_Fa', 'BsmtQual_Gd', 'BsmtQual_TA', 'CentralAir', 'ExterCond_Ex', 'ExterCond_Fa', 'ExterCond_Gd', 'ExterCond_Po', 'ExterCond_TA', 'ExterQual_Ex', 'ExterQual_Fa', 'ExterQual_Gd', 'ExterQual_TA', 'Exterior1st_AsbShng', 'Exterior1st_AsphShn', 'Exterior1st_BrkComm', 'Exterior1st_BrkFace', 'Exterior1st_HdBoard', 'Exterior1st_ImStucc', 'Exterior1st_MetalSd', 'Exterior1st_Plywood', 'Exterior1st_Stone', 'Exterior1st_Stucco', 'Exterior1st_VinylSd', 'Exterior1st_WdShing', 'Exterior2nd_AsphShn', 'Exterior2nd_Brk Cmn', 'Exterior2nd_BrkFace', 'Exterior2nd_CBlock', 'Exterior2nd_CmentBd', 'Exterior2nd_ImStucc', 'Exterior2nd_Other', 'Exterior2nd_Plywood', 'Exterior2nd_Stone', 'Exterior2nd_Stucco', 'Exterior2nd_Wd Sdng', 'Exterior2nd_Wd Shng', 'Fence_GdPrv', 'Fence_GdWo', 'Fence_MnPrv', 'Fence_MnWw', 'FireplaceQu_Ex', 'FireplaceQu_Fa', 'FireplaceQu_Gd', 'FireplaceQu_Po', 'FireplaceQu_TA', 'Functional_Maj1', 'Functional_Maj2', 'Functional_Min1', 'Functional_Min2', 'Functional_Mod', 'Functional_Sev', 'Functional_Typ', 'GarageCond_Ex', 'GarageCond_Fa', 'GarageCond_Gd', 'GarageCond_Po', 'GarageCond_TA', 'GarageFinish_Fin', 'GarageFinish_RFn', 'GarageFinish_Unf', 'GarageQual_Ex', 'GarageQual_Fa', 'GarageQual_Gd', 'GarageQual_Po', 'GarageQual_TA', 'HeatingQC_Ex', 'HeatingQC_Fa', 'HeatingQC_Gd', 'HeatingQC_Po', 'HeatingQC_TA', 'KitchenQual_Ex', 'KitchenQual_Fa', 'KitchenQual_Gd', 'KitchenQual_TA', 'OverallCond', 'OverallQual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling without correlation checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261430967468163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.85167684, 0.75355833, 0.86218785, 0.8618899 , 0.80140256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[fixed]\n",
    "\n",
    "model = RandomForestRegressor(100, n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955057689694927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.86198737, 0.80352694, 0.83082916, 0.82824685, 0.65293852])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[fixed]\n",
    "\n",
    "model = Lasso(alpha=105)\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.Series(model.coef_, index=X.columns)\n",
    "new_idx = S[S!=0].map(abs).sort_values().tail(67).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8353184397490298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.85651775, 0.75399192, 0.87599537, 0.86809739, 0.82198978])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = RandomForestRegressor(100, n_jobs=-1)\n",
    "# model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [0]\n",
    "while len(to_drop) > 0:\n",
    "    corrtype = df.corr()\n",
    "    corrs = corrtype.where(~np.triu(np.ones(corrtype.shape)).astype(np.bool)).applymap(abs)\n",
    "    high = corrs[corrs>0.8].dropna(how='all').dropna(how='all', axis=1)\n",
    "    high = high.apply(lambda x: x.dropna().index)\n",
    "    if len(high) == 0: break\n",
    "    high = set(high.values.ravel()) | set(high.columns.ravel())\n",
    "    to_drop = df[high].apply(lambda x: np.corrcoef(x, df.SalePrice)[0,1]).map(abs).sort_values().index[0]\n",
    "    df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1285, 209)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "    Slight improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8498286783732493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87130619, 0.84068549, 0.87645603, 0.87318342, 0.78751226])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "model = RandomForestRegressor(100, n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8447594275355279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90521844, 0.83498698, 0.86736469, 0.88124903, 0.73497799])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "model = Lasso(alpha=169)\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.Series(model.coef_, index=X.columns)\n",
    "new_idx = S[S!=0].map(abs).sort_values().tail(67).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8498681632744635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87041357, 0.82196584, 0.87741304, 0.87017147, 0.8093769 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = RandomForestRegressor(100, n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8389512868439455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90040411, 0.83676783, 0.86003491, 0.87682695, 0.72072263])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "model = Ridge(alpha = 19.63)\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884112193843936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.89680547, 0.85423059, 0.8998484 , 0.89930515, 0.89186649])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = XGBRegressor(n_jobs=-1, verbosity=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Regressor with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939679253552051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90530138, 0.86498187, 0.89454745, 0.89932857, 0.90568036])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = XGBRegressor(n_jobs=-1, verbosity=0)\n",
    "gs = GridSearchCV(model, {'learning_rate': np.logspace(-1, -0.5, 5)})\n",
    "\n",
    "gs.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(gs.best_estimator_, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9041280309146664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(df2010[new_idx], df2010.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Determine any value of *changeable* property characteristics unexplained by the *fixed* ones.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you have a model that estimates the price of a house based on its static characteristics, we can move forward with part 2 and 3 of the plan: what are the costs/benefits of quality, condition, and renovations?\n",
    "\n",
    "There are two specific requirements for these estimates:\n",
    "1. The estimates of effects must be in terms of dollars added or subtracted from the house value. \n",
    "2. The effects must be on the variance in price remaining from the first model.\n",
    "\n",
    "The residuals from the first model (training and testing) represent the variance in price unexplained by the fixed characteristics. Of that variance in price remaining, how much of it can be explained by the easy-to-change aspects of the property?\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Evaluate the effect in dollars of the renovate-able features. \n",
    "- How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have built to determine if they can make money. \n",
    "- Investigate how much of the variance in price remaining is explained by these features.\n",
    "- Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939679253552051\n",
      "-0.06291220995871086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-6.59882862e-02, -6.15254712e-02, -6.63075592e-02, -1.20768916e-01,\n",
       "        2.91823412e-05])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = XGBRegressor(n_jobs=-1, verbosity=0)\n",
    "gs = GridSearchCV(model, {'learning_rate': np.logspace(-1, -0.5, 5)})\n",
    "\n",
    "gs.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(gs.best_estimator_, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores\n",
    "\n",
    "yhat = gs.predict(X)\n",
    "res = y-yhat\n",
    "\n",
    "yy = res\n",
    "X = df[set(df.columns)&set(variable)]\n",
    "\n",
    "gs.fit(X,yy)\n",
    "\n",
    "scores = cross_val_score(gs.best_estimator_, X, yy, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8503232447710765\n",
      "-0.16709875000606775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00567811, -0.11835262, -0.36669306, -0.34993428,  0.00516431])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = RandomForestRegressor(100, n_jobs=-1)\n",
    "\n",
    "model.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores\n",
    "\n",
    "yhat = model.predict(X)\n",
    "res = y-yhat\n",
    "\n",
    "yy = res\n",
    "X = df[set(df.columns)&set(variable)]\n",
    "\n",
    "model.fit(X,yy)\n",
    "\n",
    "scores = cross_val_score(model, X, yy, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8570236166235616\n",
      "-0.04095540009753895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04450073, -0.02898882, -0.06693489, -0.03345198, -0.03090057])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "model = LassoCV(n_alphas=1000, n_jobs=-1)\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "model.fit(X,y)\n",
    "model = Lasso(alpha=model.alpha_)\n",
    "model.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores\n",
    "\n",
    "yhat = model.predict(X)\n",
    "res = y-yhat\n",
    "\n",
    "yy = res\n",
    "X = df[set(df.columns)&set(variable)]\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "\n",
    "model.fit(X,yy)\n",
    "\n",
    "scores = cross_val_score(model, X, yy, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573548977938014\n",
      "-0.03781581248727175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03458611, -0.03160238, -0.06217189, -0.02485805, -0.03586064])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "\n",
    "ridge = RidgeCV(alphas=np.logspace(-3,1,50))\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "ridge.fit(X,y)\n",
    "ridge = Ridge(alpha=ridge.alpha_)\n",
    "ridge.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(ridge, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores\n",
    "\n",
    "yhat = ridge.predict(X)\n",
    "res = y-yhat\n",
    "\n",
    "yy = res\n",
    "X = df[set(df.columns)&set(variable)]\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "\n",
    "ridge.fit(X,yy)\n",
    "\n",
    "scores = cross_val_score(model, X, yy, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8533209220288704\n",
      "-2.652589872901171e+20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.40735732e-01, -1.06386273e-01, -1.99091519e-01, -1.73082099e-01,\n",
       "       -1.32629494e+21])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.SalePrice\n",
    "X = df[new_idx]\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores\n",
    "\n",
    "yhat = model.predict(X)\n",
    "res = y-yhat\n",
    "\n",
    "yy = res\n",
    "X = df[set(df.columns)&set(variable)]\n",
    "ss = StandardScaler()\n",
    "toscale = X.columns[X.apply(lambda x: x.nunique()!=2)]\n",
    "X.loc[:, toscale] = ss.fit_transform(X[toscale])\n",
    "\n",
    "model.fit(X,yy)\n",
    "\n",
    "scores = cross_val_score(model, X, yy, cv=5)\n",
    "print(np.mean(scores))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GarageQual_Ex          10012.332247\n",
       "FireplaceQu_Ex          7557.610738\n",
       "Exterior2nd_ImStucc     7157.484455\n",
       "BsmtFinType2_ALQ        5955.832035\n",
       "GarageCond_TA           4378.700592\n",
       "BsmtQual_Fa             3915.291528\n",
       "Functional_Mod          3785.633664\n",
       "ExterQual_Fa            3707.609669\n",
       "Functional_Min1         3432.550682\n",
       "Exterior1st_BrkFace     3364.252505\n",
       "Functional_Min2         3041.104787\n",
       "BsmtFinType1_ALQ        2959.067221\n",
       "ExterCond_Ex            2895.131231\n",
       "Functional_Typ          2483.070422\n",
       "KitchenQual_Fa          2357.937924\n",
       "Exterior1st_WdShing     2301.877600\n",
       "BsmtCond_Po             2032.738375\n",
       "Exterior2nd_CmentBd     1851.360756\n",
       "BsmtFinType2_GLQ        1814.517368\n",
       "ExterCond_Fa            1636.396486\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ridge.coef_, X.columns).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior2nd_Stucco    -1413.476121\n",
       "Fence_MnWw            -1521.628528\n",
       "GarageQual_Gd         -1638.196247\n",
       "HeatingQC_Po          -1906.997089\n",
       "Functional_Maj1       -1985.759760\n",
       "BsmtFinType1_LwQ      -2180.162244\n",
       "Exterior2nd_Wd Shng   -2223.711559\n",
       "GarageQual_Po         -2237.141618\n",
       "GarageCond_Gd         -2295.867083\n",
       "Exterior2nd_Plywood   -2354.838261\n",
       "Fence_GdPrv           -2381.683182\n",
       "GarageCond_Po         -2486.860330\n",
       "FireplaceQu_Fa        -3146.284959\n",
       "Functional_Maj2       -3696.626993\n",
       "Exterior1st_ImStucc   -3787.823961\n",
       "GarageQual_TA         -3953.188048\n",
       "BsmtFinType2_BLQ      -3968.926103\n",
       "GarageQual_Fa         -4260.335817\n",
       "Exterior2nd_Stone     -4837.153069\n",
       "Functional_Sev        -7059.972803\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ridge.coef_, X.columns).sort_values(ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageQual: Garage quality\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tTypical/Average\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "       NA\tNo Garage\n",
      "\t\t\n",
      "GarageCond: Garage condition\n",
      " \n"
     ]
    }
   ],
   "source": [
    "dict_filter('GarageQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients do not seem reliable\n",
    "    Garage does not seem reliable in either ridge nor XGB\n",
    "    Fireplace seems reliable in Ridge (Qualitatively) but not XGB\n",
    "    Kitcen seems reliable in XGB (Qualitatively) but not ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GarageQual_Ex       10012.332247\n",
       "GarageCond_TA        4378.700592\n",
       "GarageCond_Fa        1035.794182\n",
       "GarageFinish_Unf     -363.869203\n",
       "GarageFinish_RFn     -566.874891\n",
       "GarageFinish_Fin    -1145.785389\n",
       "GarageQual_Gd       -1638.196247\n",
       "GarageQual_Po       -2237.141618\n",
       "GarageCond_Gd       -2295.867083\n",
       "GarageCond_Po       -2486.860330\n",
       "GarageQual_TA       -3953.188048\n",
       "GarageQual_Fa       -4260.335817\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ridge.coef_, X.columns).sort_values(ascending=False)[pd.Series(ridge.coef_, X.columns).sort_values(ascending=False).index.str.contains('Garage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GarageCond_Fa       0.029195\n",
       "GarageFinish_RFn    0.026824\n",
       "GarageQual_Gd       0.014135\n",
       "GarageCond_TA       0.013967\n",
       "GarageQual_TA       0.011669\n",
       "GarageQual_Fa       0.010957\n",
       "GarageCond_Gd       0.010824\n",
       "GarageFinish_Fin    0.008166\n",
       "GarageFinish_Unf    0.007432\n",
       "GarageQual_Ex       0.003373\n",
       "GarageQual_Po       0.000000\n",
       "GarageCond_Po       0.000000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False)[pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False).index.str.contains('Garage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu_Ex    7557.610738\n",
       "FireplaceQu_Gd     648.581420\n",
       "FireplaceQu_TA    -256.661314\n",
       "FireplaceQu_Po    -707.185794\n",
       "FireplaceQu_Fa   -3146.284959\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ridge.coef_, X.columns).sort_values(ascending=False)[pd.Series(ridge.coef_, X.columns).sort_values(ascending=False).index.str.contains('Fire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FireplaceQu_Po    0.045796\n",
       "FireplaceQu_TA    0.035792\n",
       "FireplaceQu_Ex    0.026630\n",
       "FireplaceQu_Gd    0.016848\n",
       "FireplaceQu_Fa    0.005801\n",
       "dtype: float32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False)[pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False).index.str.contains('Fire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenQual_Fa    2357.937924\n",
       "KitchenQual_Ex     550.888334\n",
       "KitchenQual_TA     385.742378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ridge.coef_, X.columns).sort_values(ascending=False)[pd.Series(ridge.coef_, X.columns).sort_values(ascending=False).index.str.contains('Kitchen')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KitchenQual_Ex    0.020487\n",
       "KitchenQual_TA    0.016267\n",
       "KitchenQual_Fa    0.014468\n",
       "dtype: float32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False)[pd.Series(gs.best_estimator_.feature_importances_, X.columns).sort_values(ascending=False).index.str.contains('Kitchen')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
